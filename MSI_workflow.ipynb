{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WorkFlow of MSI processing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import re\n",
    "import cv2\n",
    "import os\n",
    "import imageio\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pyimzml.ImzMLParser import ImzMLParser\n",
    "\n",
    "from csbdeep.models import CARE\n",
    "from PIL import Image\n",
    "from ISR.models import RRDN\n",
    "\n",
    "from miplib.data.containers.image import Image as resImage\n",
    "import miplib.analysis.resolution.fourier_ring_correlation as frc\n",
    "from miplib.data.containers.fourier_correlation_data import FourierCorrelationDataCollection\n",
    "import miplib.ui.plots.frc as frcplots\n",
    "from miplib.ui.cli import miplib_entry_point_options as options\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class for interior format to store and preprocess raw data\n",
    "\n",
    "This object also contains basic operations: save2h5, preprocess, visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(object):\n",
    "    \"\"\"\n",
    "    A structure to store the data to be preprocessed\n",
    "    \"\"\"\n",
    "    def __init__(self, data, x, y):\n",
    "        self.mzdata = data\n",
    "        self.xcoord = np.array(x)\n",
    "        self.ycoord = np.array(y)\n",
    "        self.dim_xy = np.array([max(self.xcoord), max(self.ycoord)])\n",
    "        self.common_mz = self.get_commonMZ()\n",
    "        self.lenmz = len(self.common_mz)\n",
    "        self.counts_mat = self.get_countsMatrix()\n",
    "        self.backgrd = self._get_background()\n",
    "        \n",
    "    def visual(self, mz = 256):\n",
    "        num = len(self.xcoord)\n",
    "        image = np.zeros((self.dim_xy[1], self.dim_xy[0]))\n",
    "\n",
    "        for i in range(num):\n",
    "            \n",
    "            position = np.where(np.ceil(self.mzdata[i]['mz']) == np.ceil(mz))[0]\n",
    "            if len(position) > 0:\n",
    "                image[self.ycoord[i]-1][self.xcoord[i]-1] = sum(self.mzdata[i]['count'][position])\n",
    "        fig = plt.figure(figsize = (5,5))\n",
    "        p = plt.imshow(image)\n",
    "        plt.show()\n",
    "        #cbar = fig.colorbar(p, orientation='vertical', ticks=[0, np.max(image)], shrink = 0.8)\n",
    "\n",
    "    def get_commonMZ(self):\n",
    "        common_mz = np.array([])\n",
    "        for idx in self.mzdata:\n",
    "            common_mz = np.concatenate((common_mz, np.around(self.mzdata[idx][\"mz\"], decimals=1)))\n",
    "        common_mz = np.unique(common_mz)   \n",
    "        return common_mz \n",
    "\n",
    "    def _get_background(self):\n",
    "        # Use the lowest mean value along mz axis as the background noise (which ion image shows minimum intensities)\n",
    "        mean_spectrum = np.mean(self.counts_mat.reshape(self.dim_xy[1]*self.dim_xy[0], self.lenmz), axis=0) #len(self.common_mz)), axis=0)\n",
    "        low_mz = np.argmin(mean_spectrum)\n",
    "        bg = np.mean(self.counts_mat[:, :, low_mz])\n",
    "        return bg\n",
    "\n",
    "    def _get_snr(self, image):         ########################### from Andy\n",
    "        mean_value = np.mean(image)\n",
    "        snr = 20*np.log10(mean_value / self.backgrd)\n",
    "        return snr\n",
    "\n",
    "    def _cal_snr(self, noise_img, clean_img): #################### from blog\n",
    "        # How to define noise_img?\n",
    "        noise_signal = noise_img - clean_img\n",
    "        clean_signal = clean_img\n",
    "\n",
    "        sum1 = np.sum(clean_signal**2)\n",
    "        sum2 = np.sum(noise_signal**2)\n",
    "        snr = 20*np.log10(np.sqrt(sum1) / np.sqrt(sum2))\n",
    "        return snr\n",
    "\n",
    "    def filter_lowsnr(self, criteria = 35): \n",
    "        new_idx = []\n",
    "        for idx in range(self.counts_mat.shape[2]):\n",
    "            tmp_image = self.counts_mat[:, :, idx]\n",
    "            if self._get_snr(tmp_image) > criteria:\n",
    "                new_idx.append(idx)\n",
    "        new_counts_mat = np.array(self.counts_mat[:, :, new_idx])\n",
    "        new_cmz = np.array(self.common_mz[new_idx])\n",
    "\n",
    "        self.counts_mat = new_counts_mat\n",
    "        self.common_mz = new_cmz\n",
    "\n",
    "        return new_cmz, new_counts_mat\n",
    "                \n",
    "    def get_countsMatrix(self):\n",
    "        mz_len = self.lenmz #len(self.common_mz)\n",
    "        counts_mat = np.zeros((self.dim_xy[1], self.dim_xy[0], mz_len))\n",
    "        for idx in range(mz_len):\n",
    "            for i in range(len(self.xcoord)):\n",
    "                position = np.where(np.around(self.mzdata[i][\"mz\"], decimals=1) == self.common_mz[idx])[0]\n",
    "                if len(position) > 0 and len(self.mzdata[i][\"count\"]) == len(self.mzdata[i][\"mz\"]):\n",
    "                    counts_mat[self.ycoord[i]-1, self.xcoord[i]-1, idx] = sum(self.mzdata[i][\"count\"][position])\n",
    "        return counts_mat\n",
    "    \n",
    "    def save2h5(self, outPath):\n",
    "        f = h5py.File(outPath, 'w')\n",
    "        \n",
    "        for idx in self.mzdata:\n",
    "            f.create_dataset('mz_' + str(idx), data = self.mzdata[idx][\"mz\"].astype(np.float))\n",
    "            f.create_dataset('counts_' + str(idx), data = self.mzdata[idx][\"count\"].astype(np.float))\n",
    "\n",
    "        f.create_dataset('x_coord', data = np.array(self.xcoord, dtype = np.float))\n",
    "        f.create_dataset('y_coord', data = np.array(self.ycoord, dtype = np.float))\n",
    "        f.close()\n",
    "\n",
    "    def get_mask(self):\n",
    "        img = np.sum(self.counts_mat, axis=2)\n",
    "        img = np.array((img / np.max(img))*255)\n",
    "        # tmp_img = img\n",
    "        img = np.array(Image.fromarray(img).convert('L'))\n",
    "        # img = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "        kernel = np.ones((5,5))\n",
    "\n",
    "        iterations = 10\n",
    "        for i in range(iterations):\n",
    "            edge = cv2.Canny(img, 10, 100)\n",
    "            edge = np.array(edge)   \n",
    "            dilate = cv2.dilate(edge, kernel, iterations = 1)\n",
    "            erosion = cv2.erode(dilate, kernel, iterations = 1)\n",
    "\n",
    "            img1, contours, hierarchy=cv2.findContours(erosion,cv2.RETR_CCOMP,cv2.CHAIN_APPROX_NONE)\n",
    "            image = cv2.drawContours(img, contours, 0, (255, 255, 255), -1)\n",
    "            break\n",
    "\n",
    "        res_img = np.zeros((img.shape[0], img.shape[1]))\n",
    "        for i in range(img.shape[0]):\n",
    "            for j in range(img.shape[1]):\n",
    "                if img[i][j] == 255:\n",
    "                    res_img[i][j] = 255 #tmp_img[i][j]\n",
    "\n",
    "        return res_img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TempData(object):\n",
    "    \"\"\"\n",
    "    A structure to store the data to be preprocessed\n",
    "    \"\"\"\n",
    "    def __init__(self, dim_xy, cz, counts_mat):\n",
    "        \n",
    "        self.dim_xy = dim_xy\n",
    "        self.common_mz = cz\n",
    "        self.lenmz = len(self.common_mz)\n",
    "        self.counts_mat = counts_mat\n",
    "        self.backgrd = self._get_background()\n",
    "        \n",
    "    def visual(self, mz = 256):\n",
    "        num = len(self.xcoord)\n",
    "        image = np.zeros((self.dim_xy[1], self.dim_xy[0]))\n",
    "\n",
    "        for i in range(num):\n",
    "            \n",
    "            position = np.where(np.ceil(self.mzdata[i]['mz']) == np.ceil(mz))[0]\n",
    "            if len(position) > 0:\n",
    "                image[self.ycoord[i]-1][self.xcoord[i]-1] = sum(self.mzdata[i]['count'][position])\n",
    "        fig = plt.figure(figsize = (5,5))\n",
    "        p = plt.imshow(image)\n",
    "        plt.show()\n",
    "        #cbar = fig.colorbar(p, orientation='vertical', ticks=[0, np.max(image)], shrink = 0.8)\n",
    "\n",
    "    def get_commonMZ(self):\n",
    "        common_mz = np.array([])\n",
    "        for idx in self.mzdata:\n",
    "            common_mz = np.concatenate((common_mz, np.around(self.mzdata[idx][\"mz\"], decimals=1)))\n",
    "        common_mz = np.unique(common_mz)   # 8002\n",
    "        return common_mz #[:151]\n",
    "\n",
    "    def _get_background(self):\n",
    "        # Use the lowest mean value along mz axis as the background noise (which ion image shows minimum intensities)\n",
    "        mean_spectrum = np.mean(self.counts_mat.reshape(self.dim_xy[1]*self.dim_xy[0], self.lenmz), axis=0) #len(self.common_mz)), axis=0)\n",
    "        low_mz = np.argmin(mean_spectrum)\n",
    "        bg = np.mean(self.counts_mat[:, :, low_mz])\n",
    "        return bg\n",
    "\n",
    "    def _get_snr(self, image):         ########################### from Andy\n",
    "        mean_value = np.mean(image)\n",
    "        snr = 20*np.log10(mean_value / self.backgrd)\n",
    "        return snr\n",
    "\n",
    "    def _cal_snr(self, noise_img, clean_img): #################### from blog\n",
    "        # How to define noise_img?\n",
    "        noise_signal = noise_img - clean_img\n",
    "        clean_signal = clean_img\n",
    "\n",
    "        sum1 = np.sum(clean_signal**2)\n",
    "        sum2 = np.sum(noise_signal**2)\n",
    "        snr = 20*np.log10(np.sqrt(sum1) / np.sqrt(sum2))\n",
    "        return snr\n",
    "\n",
    "    def filter_lowsnr(self, criteria = 35): # or we can combine this inside model processing (save time)\n",
    "        new_idx = []\n",
    "        for idx in range(self.counts_mat.shape[2]):\n",
    "            tmp_image = self.counts_mat[:, :, idx]\n",
    "            if self._get_snr(tmp_image) > criteria:\n",
    "                new_idx.append(idx)\n",
    "        new_counts_mat = np.array(self.counts_mat[:, :, new_idx])\n",
    "        new_cmz = np.array(self.common_mz[new_idx])\n",
    "\n",
    "        self.counts_mat = new_counts_mat\n",
    "        self.common_mz = new_cmz\n",
    "\n",
    "        return new_cmz, new_counts_mat\n",
    "                \n",
    "    def get_countsMatrix(self):\n",
    "        mz_len = self.lenmz #len(self.common_mz)\n",
    "        counts_mat = np.zeros((self.dim_xy[1], self.dim_xy[0], mz_len))\n",
    "        for idx in range(mz_len):\n",
    "            for i in range(len(self.xcoord)):\n",
    "                position = np.where(np.around(self.mzdata[i][\"mz\"], decimals=1) == self.common_mz[idx])[0]\n",
    "                if len(position) > 0 and len(self.mzdata[i][\"count\"]) == len(self.mzdata[i][\"mz\"]):\n",
    "                    counts_mat[self.ycoord[i]-1, self.xcoord[i]-1, idx] = sum(self.mzdata[i][\"count\"][position])\n",
    "        return counts_mat\n",
    "    \n",
    "    def save2h5(self, outPath):\n",
    "        f = h5py.File(outPath, 'w')\n",
    "        \n",
    "        for idx in self.mzdata:\n",
    "            f.create_dataset('mz_' + str(idx), data = self.mzdata[idx][\"mz\"].astype(np.float))\n",
    "            f.create_dataset('counts_' + str(idx), data = self.mzdata[idx][\"count\"].astype(np.float))\n",
    "\n",
    "        f.create_dataset('x_coord', data = np.array(self.xcoord, dtype = np.float))\n",
    "        f.create_dataset('y_coord', data = np.array(self.ycoord, dtype = np.float))\n",
    "        f.close()\n",
    "\n",
    "    def get_mask(self):\n",
    "        img = np.sum(self.counts_mat, axis=2)\n",
    "        img = np.array((img / np.max(img))*255)\n",
    "        # tmp_img = img\n",
    "        img = np.array(Image.fromarray(img).convert('L'))\n",
    "        # img = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "        kernel = np.ones((5,5))\n",
    "\n",
    "        #iterations = 1\n",
    "        #for i in range(iterations):\n",
    "        edge = cv2.Canny(img, 20, 50)\n",
    "        edge = np.array(edge)   \n",
    "        dilate = cv2.dilate(edge, kernel, iterations = 1)\n",
    "        erosion = cv2.erode(dilate, kernel, iterations = 1)\n",
    "\n",
    "        contours, hierarchy=cv2.findContours(erosion,cv2.RETR_CCOMP,cv2.CHAIN_APPROX_NONE)\n",
    "        image = cv2.drawContours(img, contours, 0, (255, 255, 255), -1)\n",
    "\n",
    "        res_img = np.zeros((img.shape[0], img.shape[1]))\n",
    "        for i in range(img.shape[0]):\n",
    "            for j in range(img.shape[1]):\n",
    "                if img[i][j] == 255:\n",
    "                    res_img[i][j] = 255 #tmp_img[i][j]\n",
    "\n",
    "        return res_img\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class for model processing\n",
    "\n",
    "This object contains two trainend DL models for MS imaging enhancement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Process(object):\n",
    "    \"\"\"\n",
    "    The processing of the input image data through our trained models (GAN + UNET5)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.gan_weights = \"D:/BMR-DS/Project_2/Code/weights/rrdn-C4-D3-G32-G032-T10-x4_best-val_generator_loss_epoch051.hdf5\"\n",
    "        self.unet5_weights = \"D:/BMR-DS/Project_2/Code/weights\"\n",
    "\n",
    "        self.unet5Model = self.unet5_load_weights()\n",
    "        self.gan_load_weights()\n",
    "\n",
    "    def unet5_load_weights(self):\n",
    "        #print(\"Loading UNET5 weights...\")\n",
    "        unet5Model = CARE(config = None, name = '400s_40ep_0.5n', basedir = self.unet5_weights)\n",
    "        print(\"Done.\")\n",
    "        return unet5Model\n",
    "\n",
    "    def gan_load_weights(self):\n",
    "        self.ganModel = RRDN(arch_params={'C': 4, 'D':3, 'G':32, 'G0':32, 'T': 10, 'x':4})\n",
    "        print(\"Loading GAN weights...\")\n",
    "        self.ganModel.model.load_weights(self.gan_weights)\n",
    "        print(\"Done.\")\n",
    "        \n",
    "    def gan_enhance(self, image, saveFlag = False, outPath = '', format = 'png'):\n",
    "        # image is 3-D version\n",
    "        #print(\"Processing single image by ESRGAN...\")\n",
    "        gan_image = self.ganModel.predict(image)\n",
    "\n",
    "        if saveFlag and format == '.png':\n",
    "            self.save2png(gan_image, outPath)\n",
    "\n",
    "        return gan_image\n",
    "\n",
    "    def unet5_denoise(self, image, saveFlag = False, outPath = ''):\n",
    "        # image is 2-D version\n",
    "        #print(\"Processing single image by UNET5...\")\n",
    "        unet5_image = self.unet5Model.predict(image, axes = 'YX')\n",
    "\n",
    "        if saveFlag and format == '.png':\n",
    "            self.save2png(unet5_image, outPath, format)\n",
    "\n",
    "        return unet5_image\n",
    "\n",
    "    def gan_unet5(self, image, saveFlag = False, outPath = '', format = '.png'):\n",
    "        # image is 3-D version\n",
    "        print(\"Processing single image by ESRGAN and UNET5...\")\n",
    "        gan_image = self.ganModel.predict(image)\n",
    "        unet5_image = self.unet5Model.predict(gan_image[:, :, 0], axes = 'YX')\n",
    "        \n",
    "        if saveFlag and format == '.png':\n",
    "            self.save2png(unet5_image, outPath)\n",
    "\n",
    "        return unet5_image\n",
    "\n",
    "    def save2png(self, image, outPath): ## image name??\n",
    "        saved_image = Image.fromarray(image)\n",
    "        saved_image.save(outPath)\n",
    "\n",
    "    def plot_original_image(self, image):\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.imshow(image[:,:,0])\n",
    "        plt.title(\"Original Image\",fontsize = 30)\n",
    "\n",
    "    def plot_gan_image(self, image):\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.imshow(image[:, :, 0])\n",
    "        plt.title(\"ESRGAN Image\",fontsize = 30)\n",
    "\n",
    "    def plot_unet5_image(self, image):\n",
    "        plt.figure(figsize=(10,8))\n",
    "        plt.imshow(image[:,:])\n",
    "        plt.title(\"UNET5 Image\",fontsize = 30)\n",
    "    \n",
    "    def plot_all(self, image, gan_image, unet5_image):\n",
    "        plt.figure(figsize=(10, 8))\n",
    "\n",
    "        plt.subplot(131)\n",
    "        plt.imshow(image[:, :, 0])\n",
    "        plt.title(\"Original Image\")\n",
    "\n",
    "        plt.subplot(132)\n",
    "        plt.imshow(gan_image[:, :, 0])\n",
    "        plt.title(\"ESRGAN Image\")\n",
    "\n",
    "        plt.subplot(133)\n",
    "        plt.imshow(unet5_image[:,:])\n",
    "        plt.title(\"ESRGAN+UNET5 Image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class FRC to calculate resolution using FRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FRC(object):\n",
    "    def __init__(self, spacing = [100.0, 100.0]):\n",
    "        self.spacing = spacing # physical size of each pixel (um)\n",
    "        #self.image = resImage(image - image.min(), self.spacing)\n",
    "        self.args = self.setup()\n",
    "\n",
    "    def setup(self):\n",
    "        args_list = (\"None --bin-delta=1  --frc-curve-fit-type=smooth-spline \"  \n",
    "             \" --resolution-threshold-criterion=fixed\").split() # half-bit\n",
    "\n",
    "        args = options.get_frc_script_options(args_list)\n",
    "\n",
    "        return args\n",
    "        \n",
    "    def image2Image(self, image):\n",
    "        image = resImage(image, self.spacing)\n",
    "        return image\n",
    "\n",
    "    def get_resolution(self, image):\n",
    "        # image is in resImage format\n",
    "        image = self.image2Image(image)\n",
    "        frc_results = FourierCorrelationDataCollection()\n",
    "\n",
    "        frc_results[0] = frc.calculate_single_image_frc(image, self.args)\n",
    "        #frcplots.plot_resolution_curves(frc_results,size = (5,5))\n",
    "        resolution = frc_results[0].resolution[\"resolution\"]\n",
    "\n",
    "        return resolution\n",
    "\n",
    "    def plot_curve_without_fitting(self, image):\n",
    "        # Cannot get the resolution\n",
    "        image = self.image2Image(image)\n",
    "        frc_results = FourierCorrelationDataCollection()\n",
    "\n",
    "        frc_results = frc.calculate_single_image_frc_without_fit(image, self.args)\n",
    "        X = frc_results[0].correlation[\"frequency\"]\n",
    "        Y = frc_results[0].correlation[\"correlation\"]\n",
    "        print(\"Frequency: \\n {}\".format(X))\n",
    "        print(\"Correlation: \\n {}\".format(Y))\n",
    "\n",
    "        # Plot the result without fitting\n",
    "        plt.figure(figsize=(5,5))\n",
    "        plt.plot(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some functions to read or convert different format data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imzML_to_h5(inPath, outPath):\n",
    "    p = ImzMLParser(inPath)\n",
    "    f = h5py.File(outPath, 'w')\n",
    "    \n",
    "    xcoord = []\n",
    "    ycoord = []\n",
    "    for idx, (x,y,z) in enumerate(p.coordinates):\n",
    "        mzs, intensities = p.getspectrum(idx)\n",
    "        f.create_dataset('mz_' + str(idx), data = mzs.astype(np.float))\n",
    "        \n",
    "        f.create_dataset('counts_' + str(idx), data = intensities.astype(np.float))\n",
    "        xcoord.append(x)\n",
    "        ycoord.append(y)\n",
    "    f.create_dataset('x_coord', data = np.array(xcoord, dtype = np.float))\n",
    "    f.create_dataset('y_coord', data = np.array(ycoord, dtype = np.float))\n",
    "    f.close()\n",
    "\n",
    "def imzML_to_predata(inPath):\n",
    "    p = ImzMLParser(inPath)\n",
    "    data = dict()\n",
    "\n",
    "    xcoord = []\n",
    "    ycoord = []\n",
    "    for idx, (x,y,z) in enumerate(p.coordinates):\n",
    "        mzs, intensities = p.getspectrum(idx)\n",
    "        data[idx] = dict()\n",
    "        data[idx][\"count\"] = np.array(intensities.astype(np.float))\n",
    "        data[idx][\"mz\"] = np.array(mzs.astype(np.float))\n",
    "        xcoord.append(x)\n",
    "        ycoord.append(y)\n",
    "    PreData = Data(data, xcoord, ycoord)\n",
    "    return PreData\n",
    "\n",
    "def h5_to_predata(inPath):\n",
    "    f = h5py.File(inPath, 'r')\n",
    "    x = np.array(f['x_coord']).astype(np.int64)\n",
    "    y = np.array(f['y_coord']).astype(np.int64) ### !!!!!\n",
    "\n",
    "    data = dict()\n",
    "    for key in f.keys():\n",
    "        if re.match(\"counts_\", key):\n",
    "            idx = int(key[7:])\n",
    "            data[idx] = dict()\n",
    "            \n",
    "            data[idx]['count'] = np.array(f[key])\n",
    "            data[idx]['mz'] = np.array(f['mz_'+str(idx)])\n",
    "    PreData = Data(data, x, y)\n",
    "    f.close()\n",
    "    return PreData\n",
    "\n",
    "def countsmatrix_to_h5(counts_mat, common_mz, dim_xy, outPath):\n",
    "    f = h5py.File(outPath, 'w')\n",
    "    f.create_dataset(\"dim_xy\", data = np.array(dim_xy, dtype = np.int))\n",
    "    f.create_dataset(\"cmz\", data = np.array(common_mz, dtype = np.float))\n",
    "    f.create_dataset(\"counts_mat\", data = np.array(counts_mat, dtype = np.float))\n",
    "    f.close()\n",
    "\n",
    "def selectROI(img, mask):\n",
    "    ## check img.size == mask.size\n",
    "    res_img = np.zeros((img.shape[0], img.shape[1]))\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            if mask[i][j] == 255:\n",
    "                res_img[i][j] = img[i][j]\n",
    "    return res_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main processing cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    start = time.time()\n",
    "\n",
    "    # The path can be changed to your own.\n",
    "    fdPath = \"D:/BMR-DS/Project_2/DataSet/Test Set/Test Set H5\"\n",
    "    outfdPath = \"D:/BMR-DS/Project_2/DataSet/Test Set/Test Set Images\"\n",
    "    resfdPath = \"D:/BMR-DS/Project_2/DataSet/Test Set/Test Set Resolution\"\n",
    "    fList = os.listdir(fdPath)\n",
    "\n",
    "    Model = Process()\n",
    "    resFRC = FRC()\n",
    "    for fName in fList:\n",
    "        spacing = [100.0, 100.0]\n",
    "\n",
    "        # It works for the test set naming format, you can change for fitting your aim.\n",
    "        # Aim is to obtain the pixel size of the raw data.\n",
    "        if fName != \"A30.h5\":\n",
    "            infos = fName.split(\"_\")\n",
    "            psize = infos[6].split(\"-\")\n",
    "            spacing = [float(psize[0]), float(psize[1])]\n",
    "\n",
    "        fPath = os.path.join(fdPath, fName)\n",
    "        outPath = os.path.join(outfdPath, fName.replace(\".imzml\", \".h5\"))\n",
    "        resPath = os.path.join(resfdPath, fName.replace(\".imzml\", \".csv\"))\n",
    "\n",
    "        Predata = imzML_to_predata(fPath)\n",
    "        print(\"input data ready!\")\n",
    "        common_mz, counts_mat = Predata.filter_lowsnr()\n",
    "        \n",
    "        mask = Predata.get_mask()\n",
    "        print(\"filter and mask done!\")\n",
    "\n",
    "        enhanced_counts_mat = np.zeros((Predata.dim_xy[1], Predata.dim_xy[0], Predata.lenmz))\n",
    "        result = pd.DataFrame()\n",
    "        original = []\n",
    "        gan = []\n",
    "        gan_unet5 = []\n",
    "        index = []\n",
    "\n",
    "        for idx in range(len(common_mz)):\n",
    "            image = np.zeros((counts_mat.shape[0], counts_mat.shape[1], 3))\n",
    "            temp = np.zeros((counts_mat.shape[0], counts_mat.shape[1]))\n",
    "            for i in range(temp.shape[0]):\n",
    "                for j in range(temp.shape[1]):\n",
    "                    if mask[i][j] == 255:\n",
    "                        temp[i][j] = counts_mat[i,j,idx]\n",
    "            maxmz = np.max(temp)\n",
    "            temp = np.array((temp / maxmz)*255)\n",
    "            image[:,:,0] = temp\n",
    "            image[:,:,1] = temp\n",
    "            image[:,:,2] = temp\n",
    "            image = np.array(image)\n",
    "\n",
    "            gan_image = Model.gan_enhance(image)\n",
    "            unet_image = Model.unet5_denoise(gan_image[:,:,0])\n",
    "            unet_image = np.array(unet_image)\n",
    "            \n",
    "            if idx == 0:\n",
    "                enhanced_counts_mat = np.zeros((unet_image.shape[0], unet_image.shape[1], Predata.lenmz))\n",
    "            enhanced_counts_mat[:,:,idx] = unet_image*(maxmz/np.max(unet_image))\n",
    "\n",
    "            \n",
    "            # Calculate the resolution by FRC\n",
    "            try:\n",
    "                original.append(resFRC.get_resolution(image[:, :, 0]))\n",
    "                gan.append(resFRC.get_resolution(gan_image[:, :, 0]))\n",
    "                gan_unet5.append(resFRC.get_resolution(unet_image[:, :]))\n",
    "                index.append(common_mz[idx])\n",
    "            except:\n",
    "                continue\n",
    "        print(\"images restoration done!\")\n",
    "\n",
    "        result['mz'] = index\n",
    "        result['original'] = original\n",
    "        result['ESRGAN'] = gan\n",
    "        result['ESRGAN_UNET5'] = gan_unet5\n",
    "        result.to_csv(resPath)\n",
    "        countsmatrix_to_h5(enhanced_counts_mat, common_mz, Predata.dim_xy, outPath)\n",
    "\n",
    "        break\n",
    "    print(\"Time: {}.\".format(time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some code for multiprocessing\n",
    "\n",
    "If your PC or server can support the multiple processing, you can try and change the code to save execution time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import multiprocessing\n",
    "def load_process(fPath, outPath, resPath):\n",
    "    # read data\n",
    "    f = h5py.File(fPath, 'r')\n",
    "    counts_mat = np.array(f[\"counts_mat\"])\n",
    "    dim_xy = np.array(f[\"dim_xy\"])\n",
    "    common_mz = np.array(f[\"cmz\"])\n",
    "    f.close()\n",
    "    \n",
    "    # set up for spacing\n",
    "    if fName != \"A30.h5\":\n",
    "        infos = fName.split(\"_\")\n",
    "        psize = infos[6].split(\"-\")\n",
    "        spacing = [float(psize[0]), float(psize[1])]\n",
    "    \n",
    "    Predata = TempData(dim_xy, common_mz, counts_mat)\n",
    "    common_mz, counts_mat = Predata.filter_lowsnr()\n",
    "    \n",
    "    # variables for results\n",
    "    enhanced_counts_mat = np.zeros((Predata.dim_xy[1], Predata.dim_xy[0], Predata.lenmz))\n",
    "    result = pd.DataFrame()\n",
    "    original = []\n",
    "    gan = []\n",
    "    gan_unet5 = []\n",
    "    index = []\n",
    "    print(\"Total ion images : {}.\".format(len(common_mz)))\n",
    "    \n",
    "    for idx in range(len(common_mz)):\n",
    "          \n",
    "        image = np.zeros((counts_mat.shape[0], counts_mat.shape[1], 3))\n",
    "        tmp = counts_mat[:,:,idx]\n",
    "        maxmz = np.max(tmp)\n",
    "        tmp = np.array((tmp / maxmz)*255)\n",
    "        \n",
    "        image[:,:,0] = tmp #counts_mat[:,:,idx]\n",
    "        image[:,:,1] = tmp #counts_mat[:,:,idx]\n",
    "        image[:,:,2] = tmp #counts_mat[:,:,idx]\n",
    "        image = np.array(image)\n",
    "        #maxmz = np.max(image[:,:,0])\n",
    "        \n",
    "        # model restoration\n",
    "        gan_image = Model.gan_enhance(image)\n",
    "        unet_image = Model.unet5_denoise(gan_image[:,:,0])\n",
    "        unet_image = np.array(unet_image)\n",
    "        unet_image[unet_image<0] = 0\n",
    "        \n",
    "        if idx == 0:\n",
    "            enhanced_counts_mat = np.zeros((unet_image.shape[0], unet_image.shape[1], Predata.lenmz))\n",
    "        \n",
    "        try:\n",
    "            original.append(resFRC.get_resolution(image[:, :, 0], spacing))\n",
    "            gan.append(resFRC.get_resolution(gan_image[:, :, 0], spacing))\n",
    "            gan_unet5.append(resFRC.get_resolution(unet_image[:, :], spacing))\n",
    "            index.append(common_mz[idx])\n",
    "        except:\n",
    "            continue\n",
    "          \n",
    "    result['mz'] = index\n",
    "    result['original'] = original\n",
    "    result['ESRGAN'] = gan\n",
    "    result['ESRGAN_UNET5'] = gan_unet5\n",
    "    result.to_csv(resPath)\n",
    "    countsmatrix_to_h5(enhanced_counts_mat, common_mz, Predata.dim_xy, outPath)\n",
    "        \n",
    "if __name__ == \"__main__\": \n",
    "    fdPath = \"D:/BMR-DS/Project_2/DataSet/Test Set/Test Set H5\"\n",
    "    outfdPath = \"D:/BMR-DS/Project_2/DataSet/Test Set/Test Set Images\"\n",
    "    resfdPath = \"D:/BMR-DS/Project_2/DataSet/Test Set/Test Set Resolution\"\n",
    "    fList = os.listdir(fdPath)\n",
    "    \n",
    "    s = time.time()\n",
    "    spacing = [100.0, 100.0]\n",
    "    #_processes = [] # multiple Process set up!\n",
    "    Model = Process()\n",
    "    resFRC = FRC()\n",
    "    \n",
    "    \n",
    "    for fName in fList:\n",
    "        if fName.find(\".ipynb_checkpoints\")>=0:\n",
    "            continue\n",
    "        print(\"{} is processing...\".format(fName))\n",
    "        fPath = os.path.join(fdPath, fName)\n",
    "        outPath = os.path.join(outfdPath, fName)\n",
    "        resPath = os.path.join(resfdPath, fName.replace(\".h5\", \".csv\"))\n",
    "        load_process(fPath, outPath, resPath)\n",
    "        print(\"Done! Time: {}.\".format(time.time()-s))\n",
    "        #_process = multiprocessing.Process(target=load_process, args=(fPath, outPath, resPath))\n",
    "        #_process.start()\n",
    "        #_processes.append(_process)\n",
    "    #for _process in _processes:\n",
    "    #    _process.join()\n",
    "\n",
    "    print(time.time()-s)\n",
    "    with open(\"DataSet/time.txt\", \"a\") as f:\n",
    "        f.write(str(time.time()-s))\n",
    "\n",
    "    \n",
    "\n",
    "'''\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def load_process(fName):\n",
    "    if \n",
    "    fPath = os.path.join(fdPath, fName)\n",
    "    f = h5py.File(fPath, 'r')\n",
    "    counts_mat = np.array(f[\"counts_mat\"])\n",
    "    dim_xy = np.array(f[\"dim_xy\"])\n",
    "    common_mz = np.array(f[\"cmz\"])\n",
    "    f.close()\n",
    "    \n",
    "if __name__ == \"__main__\": \n",
    "    startT = time.time()\n",
    "    fdPath = \"DataSet/Test Set H5\"\n",
    "    fList = os.listdir(fdPath)\n",
    "    \n",
    "    pool = Pool()\n",
    "    pool.map(load_process, fList)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    print(time.time()-startT)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single image processing -- from raw to resolution\n",
    "\n",
    "Only extract one image from raw data\n",
    "\n",
    "The MS image is generated from choosing one peak (mz=256) from raw data cube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_image(inPath, mz = 255):\n",
    "    if re.match(\"(.*)\\.h5$\", inPath):\n",
    "        Predata = h5_to_predata(inPath)\n",
    "    elif re.match(\"(.*)\\.imzml$\", inPath):\n",
    "        Predata = imzML_to_predata(inPath)\n",
    "    \n",
    "    #Predata.visual()\n",
    "\n",
    "    # Model processing\n",
    "    Model = Process()\n",
    "    image = Predata.transfer2image(mz)\n",
    "    gan_image = Model.gan_enhance(image)\n",
    "    unet_image = Model.unet5_denoise(gan_image[:,:,0])\n",
    "\n",
    "    # Plot all images\n",
    "    Model.plot_all(image, gan_image, unet_image)\n",
    "    \n",
    "    # Calculate resolution\n",
    "    resFRC = FRC()\n",
    "    ori = resFRC.get_resolution(image[:, :, 0])\n",
    "    enh = resFRC.get_resolution(gan_image[:, :, 0])\n",
    "    den = resFRC.get_resolution(unet_image)\n",
    "\n",
    "    return (ori, enh, den)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple images processing -- from images to resolution\n",
    "\n",
    "The input is a folder of .png format images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_multiple_images(fdrPath, save = False, outPath = None):\n",
    "    frc_results = dict()\n",
    "    resFRC = FRC()\n",
    "\n",
    "    flist = os.listdir(fdrPath)\n",
    "    for f in flist:\n",
    "        fpath = os.path.join(fdrPath, f)\n",
    "        image = imageio.imread(fpath)\n",
    "        try:\n",
    "            frc_results[f] = resFRC.get_resolution(image)\n",
    "        except:\n",
    "            print(\"{} cannot be sovled.\".format(f))        \n",
    "\n",
    "    if save:\n",
    "        result = pd.DataFrame()\n",
    "        result[\"file name\"] = frc_results.keys()\n",
    "        result[\"resolution\"] = frc_results.values()\n",
    "        result.to_excel(outPath)\n",
    "        \n",
    "    return frc_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw data processing -- from raw to resolution\n",
    "\n",
    "The input is the imzML format raw data.\n",
    "\n",
    "First, transfer the imzML data to numpy_image; Then, process and solve the numpy_image.\n",
    "\n",
    "How to get \"count_matrix.h5\", normalise the mz vector. (different types of tissue need the same method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def process_raw_data(inPath):\n",
    "    if re.match(\"(.*)\\.h5$\", inPath):\n",
    "        Predata = h5_to_predata(inPath)\n",
    "    elif re.match(\"(.*)\\.imzml$\", inPath):\n",
    "        Predata = imzML_to_predata(inPath)\n",
    "\n",
    "    Model = Process()\n",
    "    dataset = Predata\n",
    "    enh_dataset = dict()\n",
    "    resolution_dataset = dict()\n",
    "    for i in dataset:\n",
    "        image = np.array(dataset[i])\n",
    "        enh_image = Model.gan_unet5(image)\n",
    "        enh_dataset[i] = enh_image\n",
    "        \n",
    "        resFRC = FRC()\n",
    "        resolution_dataset[i] = resFRC.get_resolution(enh_image[:, :])\n",
    "\n",
    "    return enh_dataset, resolution_dataset\n",
    "'''\n",
    "def process_raw_data(inPath):\n",
    "    if re.match(\"(.*)\\.h5$\", inPath):\n",
    "        Predata = h5_to_predata(inPath)\n",
    "    elif re.match(\"(.*)\\.imzml$\", inPath):\n",
    "        Predata = imzML_to_predata(inPath)\n",
    "\n",
    "    Model = Process()\n",
    "       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('miplib')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6311569592bb816c5fc331b4589ce59e5fc5a973abd68897711765ac402d3d40"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
